##  ğŸ–¼ï¸RAG Multimodale

RAG Images Ã¨ un'applicazione che utilizza tecniche di Retrieval-Augmented Generation (RAG) per analizzare immagini, generare descrizioni automatiche e rispondere a domande in linguaggio naturale. Combina il modello BLIP per la generazione di caption, Milvus o FAISS per la ricerca vettoriale e un LLM locale (es. LLaMA 2) per la generazione delle risposte.


---

## Anteprima

![Project Demo GIF](images/gif.gif)

---

## ğŸš€FunzionalitÃ 
ğŸ“· Caricamento immagini con descrizione automatica tramite BLIP

ğŸ” Indicizzazione embedding in Milvus

ğŸ’¬ Domande in linguaggio naturale con risposte generate da un LLM via Ollama

ğŸ—‚ï¸ Precaricamento automatico di immagini da una cartella (images_folder/images)

ğŸŒ Supporto multilingua (prompt personalizzabile).

âš¡ Interfaccia web semplice e interattiva (Streamlit).

ğŸ§ª Test automatici su componenti chiave.

---

## ğŸ“¦ Requisiti
Python â‰¥ 3.8

streamlit, pillow, torch, transformers, sentence-transformers

faiss-cpu oppure pymilvus se usi Milvus

requests, pytest



---

## Installazione

1. Clona il repository:

```bash
1. Clona il repository

git clone https://github.com/tuo-username/rag-images.git
cd rag-images
2. Crea un ambiente virtuale
Windows:

python -m venv venv
.\venv\Scripts\activate
macOS/Linux:

python -m venv venv
source venv/bin/activate
3. Installa le dipendenze

pip install -r requirements.txt
(Opzionale) Configura eventuali variabili d'ambiente (es. API key, endpoint personalizzati)
```


```bash
âš™ï¸ Avvio dei Servizi
ğŸ§  Avvia Milvus con Docker
Metodo 1 - Docker Compose:

docker-compose -f docker/milvus.yaml up -d
Metodo 2 - Docker singolo comando:

docker run -d --name milvus-standalone -p 19530:19530 -p 19121:19121 milvusdb/milvus:latest


Controlla che Milvus sia attivo:

docker ps
Dovresti vedere milvus-standalone in esecuzione.

Per fermare Milvus:

docker stop milvus-standalone
Per rimuoverlo completamente:

docker rm milvus-standalone

ğŸ§  Avvia Ollama
Vai su https://ollama.com/ e installalo per il tuo sistema operativo.

Apri il terminale ed esegui:

ollama serve
In un altro terminale, scarica il modello desiderato (es. LLaMA 2):

ollama pull llama2:7b
Oppure usa una versione specifica, adatta alla tua GPU.

Avvia il modello:

ollama run llama2

ps: io ho utilizzato il model="llama3.2:1b perchÃ¨ piÃ¹ adatto alla GPU
OLLAMA: here the documentation https://github.com/ollama/ollama)

Vai sul sito di https://ollama.com/
fai download per utilizzarlo localmente

Ollama ha una REST API per far partire e testare i modelli:
http://localhost:11434/api/generate


Avvia l'app:
streamlit run app.py

oppure Se usi Windows, a volte conviene lanciare Streamlit cosÃ¬:

python -m streamlit run app.py


```

## ğŸ”„ Workflow
Precaricamento immagini

Un pulsante nella UI consente di caricare tutte le immagini dalla cartella images_folder/images

Ogni immagine viene descritta e indicizzata in Milvus automaticamente

Caricamento dinamico

Puoi anche caricare immagini singole tramite il form nella UI

La descrizione viene generata in automatico

Gli embeddings vengono calcolati e salvati in Milvus

Domande e risposte

Poni una domanda sull'immagine

Il sistema recupera i segmenti piÃ¹ rilevanti

Il modello LLM genera una risposta coerente e basata sul contesto visivo

## ğŸ§© Struttura del Progetto

rag-images/
â”œâ”€â”€ app.py                        # UI Streamlit e flusso principale
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ blip_model.py             # Estrazione descrizione da immagine
â”‚   â”œâ”€â”€ vector_store.py           # Gestione Milvus (embedding e retrieval)
â”‚   â”œâ”€â”€ gpt_model.py              # Streaming risposte da LLM via Ollama
â”‚   â”œâ”€â”€ utils.py                  # Funzioni di supporto generiche
â”‚   â””â”€â”€ image_embedder.py         # Estrazione degli embeddings dalle immagini
â”œâ”€â”€ images_folder/
â”‚   â””â”€â”€ images/                   # Cartella per precaricamento immagini
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ milvus.yaml               # (opzionale) Configurazione Docker Compose
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

## ğŸ§ª Test automatici 
Quando saranno attivi:

Windows:


set PYTHONPATH=. && pytest
macOS/Linux:
PYTHONPATH=. pytest

per uno specifico ad esempio:
set PYTHONPATH=. && pytest tests/test_gpt_model.py